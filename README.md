# Crawling


## 데이터 종류
- 데이터 종류
  - 정형
    - **구조화 된 데이터**
    - 대부분 출처가 **관계형데이터베이스**를 통해서 추출된 데이터 확률이 높다
    - 데이터와 구조정보(스키마)가 분리되어 있다
  - 비정형
    - 구조가 없는 데이터
    - 바이너리 데이터
      - 비디오, 오디오, 문서파일(doc,hwp..)
    - NoSQL
      - 빅데이터에서 다루는 형태
      - 로그, 접속기동등등...
  - 반정형
    - RDBMS(관계형)에서 추출(구성)하진 않았지만, 어느 정도 구조는 가지고 있다
    - JSON(키-값 형), XML -> 텍스트 기반,이기종,플랫폼, 언어(랭귀지) 독립적인 데이터 포멧 
    - HTML
    - 데이터안에 데이터+구조정보(스키마)가 같이 존재
   
## 데이터 수집 방식
- 데이터 수집 전략(난이도)
  - 모든 데이터는 그 사용에 관해서 법률적인 검토가 필요하다
  - level 1
    - 정형/반정형된 데이터가 대상(일반론)
    - 종류
      - 사내 데이터
      - 공공 데이터(국가기관, 민관, )
      - 경쟁 대회 데이터(캐글, 데이콘, 아레나, 지자체,..)
        - 기간이 지나면 미제공 할수 있음
      - 국책
        - AI허브(https://aihub.or.kr/)
      - 바우처
        - 국가에서 데이터 구매시 사용하라고 제공하는 구매비용제공쿠폰(신청후 심사후 제공)
        - 데이터 거래소(https://kdx.kr)
---
- 인터넷 통해서 직접적 수집(레벨 1에서는 내가 원하는 데이터를 얻을수 없었다)
  - level 2
    - OPEN api 활용
    - 특정기업의  공개용 API를 이용하여 수집
    - 일일 쿼터량 제한
    - 데이터는 반정형 데이터(출처는 정형 데이터) - xml or json

  - level 3
    - Web Scraping(웹스크래핑)
    - 웹사이트 접속후 어떤 액션도 없이 바로 로딩된 html을 긁어서, 파싱후 데이터 추출
    - 환율, 위키피디아, ...
    - BS4

  - level 4
    - Crawling(크롤링)
    - 사용자의 노력이 들어가서 특정 정보에 접근할수 있는 사이트가 대상
      - 로그인, 스크롤, 클릭, ajax,....
      - 다른 관점에서는 매크로라고 표현함
      - 과거 php, js, 현재 python으로 많이함
    - Selenium
